{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "import lightgbm as lgbm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier, cv, Pool\n",
    "import scikitplot as skplt\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, tpe, partial\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr, chi2_contingency\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import rc\n",
    "\n",
    "import datetime\n",
    "from dateutil import relativedelta\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.graphics.api import abline_plot # For visualling evaluating predictions.\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "import warnings # For handling error messages.\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn.metrics as met\n",
    "from sklearn import linear_model, preprocessing, model_selection, svm, datasets\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, RFE\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression, Lasso\n",
    "from sklearn.metrics import plot_confusion_matrix, auc, confusion_matrix, classification_report, accuracy_score, roc_curve, roc_auc_score, plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import scale, StandardScaler, LabelEncoder, MinMaxScaler, Binarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from bayes_opt.util import load_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset is split into 1,000 JSON files, each about 35MB.  Each contains 1,000 complete playlists.  \n",
    "## Each playlist has 4>x>251 tracks, with x>2 unique artists, and with x>1 unique albums.  \n",
    "\n",
    "number of playlists 1000000  \n",
    "number of tracks 66346428  \n",
    "number of unique tracks 2262292  \n",
    "number of unique albums 734684  \n",
    "number of unique artists 295860  \n",
    "mean playlist length 66.346428  \n",
    "mode playlist length 20   \n",
    "top track: HUMBLE. by Kendrick Lamar in 46574 playlists  \n",
    "top artist: 847160 tracks by Drake   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's the ReadMe\n",
    "\n",
    "## Detailed description\n",
    "The Million Playlist Dataset consists of 1,000 slice files. These files have the naming convention of:\n",
    "\n",
    "mpd.slice._STARTING\\_PLAYLIST\\_ID\\_-\\_ENDING\\_PLAYLIST\\_ID_.json\n",
    "\n",
    "For example, the first 1,000 playlists in the MPD are in a file called \n",
    "`mpd.slice.0-999.json` and the last 1,000 playlists are in a file called\n",
    "`mpd.slice.999000-999999.json`.\n",
    "\n",
    "Each slice file is a JSON dictionary with two fields:\n",
    "*info* and *playlists*.\n",
    "\n",
    "### `info` Field\n",
    "The info field is a dictionary that contains general information about the particular slice:\n",
    "\n",
    "   * **slice** - the range of slices that in in this particular file - such as 0-999\n",
    "   * ***version*** -  - the current version of the MPD (which should be v1)\n",
    "   * ***description*** - a description of the MPD\n",
    "   * ***license*** - licensing info for the MPD\n",
    "   * ***generated_on*** - a timestamp indicating when the slice was generated.\n",
    "\n",
    "### `playlists` field \n",
    "This is an array that typically contains 1,000 playlists. Each playlist is a dictionary that contains the following fields:\n",
    "\n",
    "\n",
    "* ***pid*** - integer - playlist id - the MPD ID of this playlist. This is an integer between 0 and 999,999.\n",
    "* ***name*** - string - the name of the playlist \n",
    "* ***description*** - optional string - if present, the description given to the playlist.  Note that user-provided playlist descrptions are a relatively new feature of Spotify, so most playlists do not have descriptions.\n",
    "* ***modified_at*** - seconds - timestamp (in seconds since the epoch) when this playlist was last updated. Times are rounded to midnight GMT of the date when the playlist was last updated.\n",
    "* ***num_artists*** - the total number of unique artists for the tracks in the playlist.\n",
    "* ***num_albums*** - the number of unique albums for the tracks in the playlist\n",
    "* ***num_tracks*** - the number of tracks in the playlist\n",
    "* ***num_followers*** - the number of followers this playlist had at the time the MPD was created. (Note that the follower count does not including the playlist creator)\n",
    "* ***num_edits*** - the number of separate editing sessions. Tracks added in a two hour window are considered to be added in a single editing session.\n",
    "* ***duration_ms*** - the total duration of all the tracks in the playlist (in milliseconds)\n",
    "* ***collaborative*** -  boolean - if true, the playlist is a collaborative playlist. Multiple users may contribute tracks to a collaborative playlist.\n",
    "* ***tracks*** - an array of information about each track in the playlist. Each element in the array is a dictionary with the following fields:\n",
    "   * ***track_name*** - the name of the track\n",
    "   * ***track_uri*** - the Spotify URI of the track\n",
    "   * ***album_name*** - the name of the track's album\n",
    "   * ***album_uri*** - the Spotify URI of the album\n",
    "   * ***artist_name*** - the name of the track's primary artist\n",
    "   * ***artist_uri*** - the Spotify URI of track's primary artist\n",
    "   * ***duration_ms*** - the duration of the track in milliseconds\n",
    "   * ***pos*** - the position of the track in the playlist (zero-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out the first 1000 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mpd.slice.0-999.json') as f:\n",
    "  df = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['playlists'] \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's the first playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I guess the best way to find similar songs is by finding which songs are on the same playlists.  I'll try making a list of tracks first.  Tracks by different artists could have the same name, so I'll use the Spotify track URI (User Resource Indicator) as the unique label.  We end up with 67,503 tracks from the first 1,000 playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTracks = []\n",
    "for x in df:\n",
    "    for y in x['tracks']:\n",
    "        allTracks.append([y['track_uri'], y['artist_name'], y['track_name'], x['pid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTracks = pd.DataFrame(allTracks, columns=['Spotify Track URI', 'Artist Name', 'Track Name', 'Playist ID #'])\n",
    "len(allTracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allTracks.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So let's make a way that we could add more data.  Let's start with the first 2 parts of the dataset.  We end up getting 134,125 tracks from 2,000 playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = []\n",
    "for x in range(0,2):\n",
    "    low = 1000 * x\n",
    "    high = low + 999\n",
    "    path = \"data/mpd.slice.\" + str(low) + \"-\" + str(high) + \".json\"\n",
    "    with open(path) as f:\n",
    "        df = json.load(f)\n",
    "        df = df['playlists'] \n",
    "        for y in df:\n",
    "            for z in y['tracks']:\n",
    "                everything.append([z['track_uri'], z['artist_name'], z['track_name'], y['pid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = pd.DataFrame(everything, columns=['Spotify Track URI', 'Artist Name', 'Track Name', 'Playist ID #'])\n",
    "len(everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So... if I have only the Playlist ID # and the Spotify Track URI, I could... pivot the dataframe?  And create a giant df with tracks as the dummies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlistPivot = everything.drop(['Artist Name', 'Track Name'], axis=1)\n",
    "playlistPivot['value']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlistPivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlistPivot = pd.pivot_table(playlistPivot, index='Playist ID #', columns='Spotify Track URI', values='value', aggfunc=max, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "playlistPivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So now there are 57,884 tracks (as columns) with 2000 playlists (as rows).  How should I compare how similar these tracks are?  Once I figure that out, I can maybe mark the tracks from the most similar playlist with .5 points, the next most similar with .25 points, and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlistPivot.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
